{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.learner import *\n",
    "\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/aclImdb/models/TEXT.pkl','rb') as pklf:\n",
    "    TEXT = pickle.load(pklf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_tok = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=32; bptt=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34maclImdb\u001b[0m/                    \u001b[01;34mkk_train\u001b[0m/  \u001b[01;34mmodels\u001b[0m/  wiki_en.txt  \u001b[01;34mwiki_valid\u001b[0m/\r\n",
      "cleaned-extra-kk-jokes.txt  \u001b[01;34mkk_valid\u001b[0m/  \u001b[01;34mtmp\u001b[0m/     \u001b[01;34mwiki_train\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "PATH='data/'\n",
    "\n",
    "TRN_PATH = 'kk_train/'\n",
    "VAL_PATH = 'kk_valid/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batches: 15\n",
      "unique tokens: 37392\n",
      "tokens in training set: 1\n",
      "sentences: 10576\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f'batches: {len(md.trn_dl)}\\nunique tokens: {md.nt}\\ntokens in training set: {len(md.trn_ds)}\\nsentences: {len(md.trn_ds[0].text)}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " \n",
       " Columns 0 to 10 \n",
       "   3219   3219     61     50      4     61    658  16370     36  19065     61\n",
       "      3      4   1049     45   2080   4282    171    686    137     43  11943\n",
       "   3219     43   1049      0     43      4    337    167     10     61  11943\n",
       "      4     16     43     45     61   4282     45    142      6  19065     43\n",
       "     43     50     61      0   2080     43     38     45    881     27     61\n",
       "     16     45   1049     43    605     61   3219     38     45    144  11943\n",
       "     50      0     68     61      8   4282      3   3219     38   3251     36\n",
       "     45     45      5      0   1232    263   3219      3   3219    182   1594\n",
       "  25970      0   1611    431     68   4071      4   3219      3    144      3\n",
       "     45     43     13    139     34     61     43      4   3219  16223     12\n",
       "  25970     61   1235      2   4624     38     16     43      4      9     35\n",
       "     43      0     45   4026      4   3219     50     16     43      6      8\n",
       "     61  25799     38     45     38      3     45     50     16     93    157\n",
       "  25970     45   3219     38   3219   3219   8487     61     50    339      8\n",
       "   1534     38      3   3219      3      4     45  17014     45     45      2\n",
       "      9   3219   3219      3   3219     43   8487  17014      0     38   4123\n",
       "     31      3      4   3219      4     16     43     61     45   3219     45\n",
       "     76   3219     43      4     43     50     61  17014      0      3     38\n",
       " \n",
       " Columns 11 to 21 \n",
       "     61    529   3808      3     16   1801     16     45      0     50     26\n",
       "      0     45    321   3219     50     45     50     38  22604     45    309\n",
       "      0     38     45      4     61   1801     61   3219     43   5116     84\n",
       "      4   3219     38     43   3021     43   3021      3     61     45     10\n",
       "    221      3   3219     16     45     61     45   3219   1247   5116     61\n",
       "      2   3219      3     50   3021   1801   3021      4  22604     43     97\n",
       "   1061      4   3219     61     43      6     43     43     44     61     26\n",
       "     36     43      4   3354     61     62     61     16    567   5116    418\n",
       "     21     16     43      4   3021   1197   3021     50     17     84     10\n",
       "     26     50     16   3354      6     45      6     45    309    363      6\n",
       "     45     45     50     43   1025     38  10837      0     84      3    337\n",
       "     38  10343     45     61    251   3219     62     45     10     12     61\n",
       "   3219      5   4443    461     45      3   1631      0     45   2719    461\n",
       "      3   1377     45     26     38   3219     45     43     38   1467      4\n",
       "   3219     45   4443     32   3219      4     38     61   3219     45     97\n",
       "      4  10343     43     45      3     43   3219      0      3     38     26\n",
       "     43      5     61     38   3219     16      3   7168   3219   3219    418\n",
       "     16   1377   4443   3219      4     50   3219     45      4      3     10\n",
       " \n",
       " Columns 22 to 31 \n",
       "   1847     17      3      2     50     45   3063      3     43     43\n",
       "     43     12   3219   4217     61     38     45   3219     13     16\n",
       "     45    120      4     45      0   3219   3063      4      9     50\n",
       "      0    144     43     38      0      3     43     43     45     45\n",
       "     26   6948     16   3219     43   3219     61     16     38  15062\n",
       "     10     32     50      3     61      4   3063     50   3219     45\n",
       "      2     50     61   3219      0     43   1429     45      3  15062\n",
       "  18278     45   1528      4     80     16     12  32685   3219     43\n",
       "      3    941     45     43      8     50   2719     45      4     61\n",
       "     35     38   1528     16   3219     45   1680  32685     43  15062\n",
       "   1187   3219     43     50    101   1247     45     43     16  27296\n",
       "     12      3     61     45    144      5     38     61     50     84\n",
       "     61   3219      0  17708      0      0   3219  32685     61     27\n",
       "     38      4     55     45     82      5      3    302   3679      2\n",
       "   3219     43     26  17708     29   2135   3219     24   3679   3678\n",
       "      3     16   2461     43    181     43      4     12     43     45\n",
       "   3219     50  15483     61     45     61     43   2719     61     38\n",
       "      4     45     45  17708     38   1247     16   7182   3679   3219\n",
       " [torch.cuda.LongTensor of size 18x32 (GPU 0)], Variable containing:\n",
       "      3\n",
       "      4\n",
       "   1049\n",
       "     45\n",
       "   2080\n",
       "   4282\n",
       "    171\n",
       "    686\n",
       "    137\n",
       "     43\n",
       "  11943\n",
       "      0\n",
       "     45\n",
       "    321\n",
       "   3219\n",
       "     50\n",
       "     45\n",
       "     50\n",
       "     38\n",
       "  22604\n",
       "     45\n",
       "    309\n",
       "     43\n",
       "     12\n",
       "   3219\n",
       "   4217\n",
       "     61\n",
       "     38\n",
       "     45\n",
       "   3219\n",
       "     13\n",
       "     16\n",
       "   3219\n",
       "     43\n",
       "   1049\n",
       "      0\n",
       "     43\n",
       "      4\n",
       "    337\n",
       "    167\n",
       "     10\n",
       "     61\n",
       "  11943\n",
       "      0\n",
       "     38\n",
       "     45\n",
       "      4\n",
       "     61\n",
       "   1801\n",
       "     61\n",
       "   3219\n",
       "     43\n",
       "   5116\n",
       "     84\n",
       "     45\n",
       "    120\n",
       "      4\n",
       "     45\n",
       "      0\n",
       "   3219\n",
       "   3063\n",
       "      4\n",
       "      9\n",
       "     50\n",
       "      4\n",
       "     16\n",
       "     43\n",
       "     45\n",
       "     61\n",
       "   4282\n",
       "     45\n",
       "    142\n",
       "      6\n",
       "  19065\n",
       "     43\n",
       "      4\n",
       "   3219\n",
       "     38\n",
       "     43\n",
       "   3021\n",
       "     43\n",
       "   3021\n",
       "      3\n",
       "     61\n",
       "     45\n",
       "     10\n",
       "      0\n",
       "    144\n",
       "     43\n",
       "     38\n",
       "      0\n",
       "      3\n",
       "     43\n",
       "     43\n",
       "     45\n",
       "     45\n",
       "     43\n",
       "     50\n",
       "     61\n",
       "      0\n",
       "   2080\n",
       "     43\n",
       "     38\n",
       "     45\n",
       "    881\n",
       "     27\n",
       "     61\n",
       "    221\n",
       "      3\n",
       "   3219\n",
       "     16\n",
       "     45\n",
       "     61\n",
       "     45\n",
       "   3219\n",
       "   1247\n",
       "   5116\n",
       "     61\n",
       "     26\n",
       "   6948\n",
       "     16\n",
       "   3219\n",
       "     43\n",
       "   3219\n",
       "     61\n",
       "     16\n",
       "     38\n",
       "  15062\n",
       "     16\n",
       "     45\n",
       "   1049\n",
       "     43\n",
       "    605\n",
       "     61\n",
       "   3219\n",
       "     38\n",
       "     45\n",
       "    144\n",
       "  11943\n",
       "      2\n",
       "   3219\n",
       "      3\n",
       "     50\n",
       "   3021\n",
       "   1801\n",
       "   3021\n",
       "      4\n",
       "  22604\n",
       "     43\n",
       "     97\n",
       "     10\n",
       "     32\n",
       "     50\n",
       "      3\n",
       "     61\n",
       "      4\n",
       "   3063\n",
       "     50\n",
       "   3219\n",
       "     45\n",
       "     50\n",
       "      0\n",
       "     68\n",
       "     61\n",
       "      8\n",
       "   4282\n",
       "      3\n",
       "   3219\n",
       "     38\n",
       "   3251\n",
       "     36\n",
       "   1061\n",
       "      4\n",
       "   3219\n",
       "     61\n",
       "     43\n",
       "      6\n",
       "     43\n",
       "     43\n",
       "     44\n",
       "     61\n",
       "     26\n",
       "      2\n",
       "     50\n",
       "     61\n",
       "   3219\n",
       "      0\n",
       "     43\n",
       "   1429\n",
       "     45\n",
       "      3\n",
       "  15062\n",
       "     45\n",
       "     45\n",
       "      5\n",
       "      0\n",
       "   1232\n",
       "    263\n",
       "   3219\n",
       "      3\n",
       "   3219\n",
       "    182\n",
       "   1594\n",
       "     36\n",
       "     43\n",
       "      4\n",
       "   3354\n",
       "     61\n",
       "     62\n",
       "     61\n",
       "     16\n",
       "    567\n",
       "   5116\n",
       "    418\n",
       "  18278\n",
       "     45\n",
       "   1528\n",
       "      4\n",
       "     80\n",
       "     16\n",
       "     12\n",
       "  32685\n",
       "   3219\n",
       "     43\n",
       "  25970\n",
       "      0\n",
       "   1611\n",
       "    431\n",
       "     68\n",
       "   4071\n",
       "      4\n",
       "   3219\n",
       "      3\n",
       "    144\n",
       "      3\n",
       "     21\n",
       "     16\n",
       "     43\n",
       "      4\n",
       "   3021\n",
       "   1197\n",
       "   3021\n",
       "     50\n",
       "     17\n",
       "     84\n",
       "     10\n",
       "      3\n",
       "    941\n",
       "     45\n",
       "     43\n",
       "      8\n",
       "     50\n",
       "   2719\n",
       "     45\n",
       "      4\n",
       "     61\n",
       "     45\n",
       "     43\n",
       "     13\n",
       "    139\n",
       "     34\n",
       "     61\n",
       "     43\n",
       "      4\n",
       "   3219\n",
       "  16223\n",
       "     12\n",
       "     26\n",
       "     50\n",
       "     16\n",
       "   3354\n",
       "      6\n",
       "     45\n",
       "      6\n",
       "     45\n",
       "    309\n",
       "    363\n",
       "      6\n",
       "     35\n",
       "     38\n",
       "   1528\n",
       "     16\n",
       "   3219\n",
       "     45\n",
       "   1680\n",
       "  32685\n",
       "     43\n",
       "  15062\n",
       "  25970\n",
       "     61\n",
       "   1235\n",
       "      2\n",
       "   4624\n",
       "     38\n",
       "     16\n",
       "     43\n",
       "      4\n",
       "      9\n",
       "     35\n",
       "     45\n",
       "     45\n",
       "     50\n",
       "     43\n",
       "   1025\n",
       "     38\n",
       "  10837\n",
       "      0\n",
       "     84\n",
       "      3\n",
       "    337\n",
       "   1187\n",
       "   3219\n",
       "     43\n",
       "     50\n",
       "    101\n",
       "   1247\n",
       "     45\n",
       "     43\n",
       "     16\n",
       "  27296\n",
       "     43\n",
       "      0\n",
       "     45\n",
       "   4026\n",
       "      4\n",
       "   3219\n",
       "     50\n",
       "     16\n",
       "     43\n",
       "      6\n",
       "      8\n",
       "     38\n",
       "  10343\n",
       "     45\n",
       "     61\n",
       "    251\n",
       "   3219\n",
       "     62\n",
       "     45\n",
       "     10\n",
       "     12\n",
       "     61\n",
       "     12\n",
       "      3\n",
       "     61\n",
       "     45\n",
       "    144\n",
       "      5\n",
       "     38\n",
       "     61\n",
       "     50\n",
       "     84\n",
       "     61\n",
       "  25799\n",
       "     38\n",
       "     45\n",
       "     38\n",
       "      3\n",
       "     45\n",
       "     50\n",
       "     16\n",
       "     93\n",
       "    157\n",
       "   3219\n",
       "      5\n",
       "   4443\n",
       "    461\n",
       "     45\n",
       "      3\n",
       "   1631\n",
       "      0\n",
       "     45\n",
       "   2719\n",
       "    461\n",
       "     61\n",
       "   3219\n",
       "      0\n",
       "  17708\n",
       "      0\n",
       "      0\n",
       "   3219\n",
       "  32685\n",
       "     61\n",
       "     27\n",
       "  25970\n",
       "     45\n",
       "   3219\n",
       "     38\n",
       "   3219\n",
       "   3219\n",
       "   8487\n",
       "     61\n",
       "     50\n",
       "    339\n",
       "      8\n",
       "      3\n",
       "   1377\n",
       "     45\n",
       "     26\n",
       "     38\n",
       "   3219\n",
       "     45\n",
       "     43\n",
       "     38\n",
       "   1467\n",
       "      4\n",
       "     38\n",
       "      4\n",
       "     55\n",
       "     45\n",
       "     82\n",
       "      5\n",
       "      3\n",
       "    302\n",
       "   3679\n",
       "      2\n",
       "   1534\n",
       "     38\n",
       "      3\n",
       "   3219\n",
       "      3\n",
       "      4\n",
       "     45\n",
       "  17014\n",
       "     45\n",
       "     45\n",
       "      2\n",
       "   3219\n",
       "     45\n",
       "   4443\n",
       "     32\n",
       "   3219\n",
       "      4\n",
       "     38\n",
       "     61\n",
       "   3219\n",
       "     45\n",
       "     97\n",
       "   3219\n",
       "     43\n",
       "     26\n",
       "  17708\n",
       "     29\n",
       "   2135\n",
       "   3219\n",
       "     24\n",
       "   3679\n",
       "   3678\n",
       "      9\n",
       "   3219\n",
       "   3219\n",
       "      3\n",
       "   3219\n",
       "     43\n",
       "   8487\n",
       "  17014\n",
       "      0\n",
       "     38\n",
       "   4123\n",
       "      4\n",
       "  10343\n",
       "     43\n",
       "     45\n",
       "      3\n",
       "     43\n",
       "   3219\n",
       "      0\n",
       "      3\n",
       "     38\n",
       "     26\n",
       "      3\n",
       "     16\n",
       "   2461\n",
       "     43\n",
       "    181\n",
       "     43\n",
       "      4\n",
       "     12\n",
       "     43\n",
       "     45\n",
       "     31\n",
       "      3\n",
       "      4\n",
       "   3219\n",
       "      4\n",
       "     16\n",
       "     43\n",
       "     61\n",
       "     45\n",
       "   3219\n",
       "     45\n",
       "     43\n",
       "      5\n",
       "     61\n",
       "     38\n",
       "   3219\n",
       "     16\n",
       "      3\n",
       "   7168\n",
       "   3219\n",
       "   3219\n",
       "    418\n",
       "   3219\n",
       "     50\n",
       "  15483\n",
       "     61\n",
       "     45\n",
       "     61\n",
       "     43\n",
       "   2719\n",
       "     61\n",
       "     38\n",
       "     76\n",
       "   3219\n",
       "     43\n",
       "      4\n",
       "     43\n",
       "     50\n",
       "     61\n",
       "  17014\n",
       "      0\n",
       "      3\n",
       "     38\n",
       "     16\n",
       "   1377\n",
       "   4443\n",
       "   3219\n",
       "      4\n",
       "     50\n",
       "   3219\n",
       "     45\n",
       "      4\n",
       "      3\n",
       "     10\n",
       "      4\n",
       "     45\n",
       "     45\n",
       "  17708\n",
       "     38\n",
       "   1247\n",
       "     16\n",
       "   7182\n",
       "   3679\n",
       "   3219\n",
       "   1382\n",
       "      4\n",
       "     16\n",
       "     43\n",
       "     16\n",
       "     45\n",
       "   8487\n",
       "    106\n",
       "     43\n",
       "   3219\n",
       "   3219\n",
       "     50\n",
       "     43\n",
       "   9422\n",
       "      3\n",
       "     43\n",
       "     45\n",
       "      4\n",
       "     38\n",
       "     43\n",
       "   3219\n",
       "      6\n",
       "     43\n",
       "   1830\n",
       "     38\n",
       "   1541\n",
       "   3219\n",
       "      5\n",
       "     50\n",
       "    174\n",
       "     68\n",
       "      3\n",
       " [torch.cuda.LongTensor of size 576 (GPU 0)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(md.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knock', ',', 'knock', '.', 'who', \"'s\", 'there', '!', 'buggy', '!']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.trn_ds[0].text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  3219\n",
       "     3\n",
       "  3219\n",
       "     4\n",
       "    43\n",
       "    16\n",
       "    50\n",
       "    45\n",
       " 25970\n",
       "    45\n",
       "[torch.cuda.LongTensor of size 10x1 (GPU 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.numericalize([md.trn_ds[0].text[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz = 200  # size of each embedding vector\n",
    "n_layers_act = 500     # number of hidden activations per layer\n",
    "n_layers = 3      # number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = md.get_model(opt_fn, em_sz, n_layers_act, n_layers,\n",
    "               dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_encoder('adam3_20_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9b9fb9db4640beb8fa20d599d108c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                            \n",
      "    0      5.235847   5.216734  \n",
      "    1      4.532408   4.382916                            \n",
      "    2      4.1044     4.064408                            \n",
      "    3      3.823516   3.878101                            \n",
      "    4      3.56493    3.392389                            \n",
      "    5      3.389188   3.524044                            \n",
      "    6      3.218011   3.684946                            \n",
      "    7      3.092188   3.006834                            \n",
      "    8      2.942545   3.202374                            \n",
      "    9      2.807659   3.344296                            \n",
      "    10     2.681339   2.823181                            \n",
      "    11     2.592538   3.27758                             \n",
      "    12     2.505444   3.085213                            \n",
      "    13     2.43974    3.180779                            \n",
      "    14     2.39134    3.328322                            \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.3283224]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-4, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('kkadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a47604ba50407fb4360934bea1c2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                            \n",
      "    0      2.310015   2.755177  \n",
      "    1      2.168443   2.997514                            \n",
      "    2      1.928563   3.209678                            \n",
      "    3      1.727295   2.933261                            \n",
      "    4      1.542455   3.260538                            \n",
      "    5      1.42303    3.049026                            \n",
      "    6      1.279217   2.913579                            \n",
      "    7      1.18068    3.18208                             \n",
      "    8      1.094555   3.182566                            \n",
      "    9      1.025981   3.059655                            \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.0596554]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 1, wds=1e-6, cycle_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_encoder('kkadam2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ee613de4f3420181bc6cdb517b5788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=13), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                             \n",
      "    0      1.058636   3.116266  \n",
      "    1      0.980902   2.953997                             \n",
      "    2      0.910974   2.939238                             \n",
      "    3      0.84777    3.141369                             \n",
      "    4      0.827483   2.894783                             \n",
      "    5      0.818164   3.151232                             \n",
      "    6      0.78605    3.110808                             \n",
      "    7      0.747835   3.299406                             \n",
      "    8      0.70568    3.150657                             \n",
      "    9      0.676542   3.109282                             \n",
      "    10     0.669247   3.111122                             \n",
      "    11     0.631094   3.330745                             \n",
      "    12     0.60036    3.308752                             \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.3087516]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 3, wds=1e-6, cycle_len=1, cycle_mult=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"knock knock who 's there\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=learner.model\n",
    "ss=\"\"\"knock knock who's there\"\"\"\n",
    "ss=''.join(w.lower() for w in ss)\n",
    "s = [TEXT.tokenize(ss)]\n",
    "t=TEXT.numericalize(s)\n",
    "' '.join(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size to 1\n",
    "m[0].bs=1\n",
    "# Turn off dropout\n",
    "m.eval()\n",
    "# Reset hidden state\n",
    "m.reset()\n",
    "# Get predictions from model\n",
    "res,*_ = m(t)\n",
    "# Put the batch size back to what it was\n",
    "m[0].bs=bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?', '!', '.', '<eos>', 'there', '...', ',', 'who', 'you', 'here']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nexts = torch.topk(res[-1], 10)[1]\n",
    "[TEXT.vocab.itos[o] for o in to_np(nexts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knock knock who's there \n",
      "\n",
      "<eos> knock , let 's there ? cheese cheese who who ? cheese some silly jokes ! <eos> knock , do you want one ? go out for a picnic ! <eos> knock , knock ... who 's there ! argo <unk> who ? argo down the shops for my money , just <unk> /><br knock , knock . who 's here ? bruce bruce who ? i bruce easily , do nt bother me ! <eos> knock , have ! ! <eos> knock , knock . and who 's there who ? annie - house ! <eos> let , ...\n"
     ]
    }
   ],
   "source": [
    "tk=8\n",
    "pct=.75\n",
    "print(ss,\"\\n\")\n",
    "for i in range(100):\n",
    "    if random.random()>pct:\n",
    "        n=res[-1].topk(tk)[1]\n",
    "        n = n[random.randint(0,tk-1)] if n.data[0]==0 else n[random.randint(0,tk-1)]\n",
    "    else:\n",
    "        n=res[-1].topk(2)[1]\n",
    "        n = n[1] if n.data[0]==0 else n[0]\n",
    "    print(TEXT.vocab.itos[n.data[0]], end=' ')\n",
    "    res,*_ = m(n[0].unsqueeze(0))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
