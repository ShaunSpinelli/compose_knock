{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knock Knock Joke Generator\n",
    "## Team Compose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.learner import *\n",
    "import torchtext\n",
    "from torchtext import vocab, data\n",
    "from torchtext.datasets import language_modeling\n",
    "\n",
    "from fastai.rnn_reg import *\n",
    "from fastai.rnn_train import *\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "import dill as pickle\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the training and validation paths\n",
    "TEST_PATH = 'test/'\n",
    "TRAIN_PATH = 'train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\r\n"
     ]
    }
   ],
   "source": [
    "# Number of test examples\n",
    "! ls -l {TEST_PATH} | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460\r\n"
     ]
    }
   ],
   "source": [
    "# Number of training examples\n",
    "!ls -l {TRAIN_PATH} | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_100.txt',\n",
       " 'train_101.txt',\n",
       " 'train_102.txt',\n",
       " 'train_104.txt',\n",
       " 'train_105.txt']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating lists of training and test examples\n",
    "train_files = !ls {TRAIN_PATH}\n",
    "test_files = !ls {TEST_PATH}\n",
    "train_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"knock, knock. who's there! arfur! arfur who? arfur got!\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first training examples together\n",
    "train_file = !cat {TRAIN_PATH}{train_files[0]}\n",
    "train_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the torchtext field.\n",
    "\n",
    "#required so that the tokenizer works\n",
    "spacy.load('en') \n",
    "TEXT = pickle.load(open('TEXT-adam5.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs is the number of batches that the data gets split into\n",
    "# bptt is the number of words from each batch\n",
    "bs = 16\n",
    "bptt = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 'train/', 'validation': 'test/', 'test': 'test/'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILES = dict(train=TRAIN_PATH, validation=TEST_PATH, test=TEST_PATH)\n",
    "FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_data = LanguageModelData.from_text_files(\"\", TEXT, **FILES, bs=bs, bptt=bptt, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of batches\n",
    "len(model_data.trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37392"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of vocab tokens\n",
    "model_data.nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset of the words that have been tokenized\n",
    "TEXT.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.stoi['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_vector_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_activations_per_layer = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimization_function = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = model_data.get_model(optimization_function, \n",
    "                               embedding_matrix_vector_size,\n",
    "                               hidden_activations_per_layer,\n",
    "                               number_of_layers,\n",
    "                               dropouti=0.05, \n",
    "                               dropout=0.05, \n",
    "                               wdrop=0.1, \n",
    "                               dropoute=0.02, \n",
    "                               dropouth=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This clips the learning rate\n",
    "learner.clip=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load_encoder('adam5_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb0cdcc70b946718110e92a07014acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                            \n",
      "    0      4.70394    4.037547  \n",
      "    1      3.880033   3.257333                            \n",
      "    2      3.479815   3.221597                            \n",
      "    3      3.169128   2.856732                            \n",
      "    4      2.910245   2.821475                            \n",
      "    5      2.678835   2.710077                            \n",
      "    6      2.522056   2.735424                            \n",
      "    7      2.44901    2.669336                            \n",
      "    8      2.327343   2.729415                            \n",
      "    9      2.210193   2.636024                            \n",
      "    10     2.10802    2.669223                            \n",
      "    11     2.036789   2.656643                            \n",
      "    12     1.97295    2.63354                             \n",
      "    13     1.927896   2.618145                            \n",
      "    14     1.914096   2.664956                            \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6649556109779757]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-4, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6205281df90d4379945ced884e08ebf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                            \n",
      "    0      1.946285   2.68589   \n",
      "    1      1.827705   2.752432                            \n",
      "    2      1.575973   2.798588                            \n",
      "    3      1.386097   2.807913                            \n",
      "    4      1.177162   2.875699                            \n",
      "    5      1.025995   2.856046                            \n",
      "    6      0.898376   3.002249                             \n",
      "    7      0.890061   2.906619                             \n",
      "    8      0.78586    2.914161                             \n",
      "    9      0.75588    2.99573                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.995729708843094]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.fit(3e-3, 1, wds=1e-6, cycle_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = \"knock, knock who's there\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"knock , knock who 's there\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = [TEXT.tokenize(ss)]\n",
    "t = TEXT.numericalize(s)\n",
    "' '.join(s[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[0].bs = 1\n",
    "model.eval()\n",
    "model.reset()\n",
    "res, *_ = model(t)\n",
    "model[0].bs = bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?', '!', '.', 'there', 'if', 'who', ',', '-', '...', 'again']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words = torch.topk(res[-1], 10)[1]\n",
    "[TEXT.vocab.itos[o] for o in to_np(next_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knock, knock who's there \n",
      "\n",
      "? <eos> knock , knock . who 's there ! argo ! argo who ? argo down the shops ! <eos> knock , knock . who 's there ! teresa ! teresa who ? teresa are green ! <eos> knock , knock . who 's there ! argo ! argo who ? argo down the shops ! <unk> ! <eos> knock , knock . who 's there ! carrie ! carrie who ? carrie on camping ! <eos> knock , knock . who 's there ! <unk> ! - who ? hey hey who ? hey ho , hey ho ...\n"
     ]
    }
   ],
   "source": [
    "print(ss,\"\\n\")\n",
    "for i in range(100):\n",
    "    n=res[-1].topk(10)[1]\n",
    "    n = n[random.randint(0,9)] if n.data[0]==0 else n[0]\n",
    "    print(TEXT.vocab.itos[n.data[0]], end=' ')\n",
    "    res,*_ = model(n[0].unsqueeze(0))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
